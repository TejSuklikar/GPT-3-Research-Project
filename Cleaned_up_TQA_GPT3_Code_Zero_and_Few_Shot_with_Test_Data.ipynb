{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TejSuklikar/GPT-3-Research-Project/blob/main/Cleaned_up_TQA_GPT3_Code_Zero_and_Few_Shot_with_Test_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the JSON File**"
      ],
      "metadata": {
        "id": "jeasOqu4mO19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCOWtQSCppDb"
      },
      "outputs": [],
      "source": [
        "#Library\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.read_json(\"/content/tqa_v2_test.json\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Create a Content Table where each row is either a Topic or Adjunct Topic for a given lesson.**"
      ],
      "metadata": {
        "id": "Z-_m_d48mf-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.apply import Apply\n",
        "topics = x['topics']\n",
        "adjunctTopics = x['adjunctTopics']\n",
        "\n",
        "length = x.index.stop\n",
        "i=0\n",
        "contentTable = []\n",
        "while i < length:\n",
        "  for key in topics[i].keys():\n",
        "    contentTable.append( [x['globalID'][i], x['lessonName'][i], \"Topic\", \"\", key, topics[i][key]['content']['text']])\n",
        "    j = 0\n",
        "    for key in adjunctTopics[i].keys():\n",
        "      contentID = \"A_\" + str(i*1000+j)\n",
        "      if (key != 'Vocabulary'):\n",
        "        contentTable.append( [x['globalID'][i], x['lessonName'][i], \"Adjunct Topic\", str(key), contentID, adjunctTopics[i][str(key)]['content']['text']])\n",
        "      j+=1\n",
        "  i+=1\n"
      ],
      "metadata": {
        "id": "rzopxoLj0-jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a simpler Content Table with just Topic content**"
      ],
      "metadata": {
        "id": "9K_6syvAm4EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.apply import Apply\n",
        "topics = x['topics']\n",
        "\n",
        "length = x.index.stop\n",
        "i=0\n",
        "contentqaTable = []\n",
        "while i < length:\n",
        "  for key in topics[i].keys():\n",
        "    content = topics[i][key]['content']['text']\n",
        "    contentqaTable.append([x['globalID'][i], content])\n",
        "  i+=1\n"
      ],
      "metadata": {
        "id": "g2HOQow0BbED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert the content table to a Data Frame.**"
      ],
      "metadata": {
        "id": "jFDObow7nAyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct = pd.DataFrame(contentqaTable,columns=['id','context',])"
      ],
      "metadata": {
        "id": "mJgL1lpDFPjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since there are multiple rows of content for each Lesson ID, get the unique Lesson IDs. This will be useful in constructing Prompts per lesson**"
      ],
      "metadata": {
        "id": "DpfHON3nnH_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lessonIds = ct.id.unique()\n"
      ],
      "metadata": {
        "id": "NXzekAZm9Awy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a consolidated Lesson Table with one row per Lesson, and all the associated content**"
      ],
      "metadata": {
        "id": "CAAZ8FeinYHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consolidatedLessonTable = []\n",
        "for l in lessonIds:\n",
        "  lessonContext = \"\"\n",
        "  lessonContents = ct[ct.id == l]\n",
        "  for index, row in lessonContents.iterrows():\n",
        "    lessonContext += row['context'] + \"\\n\"\n",
        "  consolidatedLessonTable.append([l,lessonContext])\n",
        "clt = pd.DataFrame(consolidatedLessonTable,columns=['id','content'])"
      ],
      "metadata": {
        "id": "7pXfdinYNn2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a Question Answer Table with the Questions, Answer Choices, and Correct Answer per row. Additionally the associated Lesson ID is also stored for looking up and joining to the Lesson Table content.**"
      ],
      "metadata": {
        "id": "srE7H6k2njGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = x['questions']\n",
        "length = x.index.stop\n",
        "i=0\n",
        "\n",
        "questionAnswerTable = []\n",
        "answerTable =[]\n",
        "while i < length:\n",
        "  for key in questions[i]['nonDiagramQuestions'].keys():\n",
        "    lessonID = x['globalID'][i]\n",
        "    lessonName = x['lessonName'][i]\n",
        "    questionID = key\n",
        "    questionText = questions[i]['nonDiagramQuestions'][key]['beingAsked']['processedText']\n",
        "    questionType = questions[i]['nonDiagramQuestions'][key]['questionType']\n",
        "    questionSubType = questions[i]['nonDiagramQuestions'][key]['questionSubType']\n",
        "    correctAnswerChoice = questions[i]['nonDiagramQuestions'][key]['correctAnswer']['processedText']\n",
        "    answerChoices = questions[i]['nonDiagramQuestions'][key]['answerChoices']\n",
        "    answerChoicesPrompt = \"\"\n",
        "    correctAnswerDetail = \"\"\n",
        "    for key2 in questions[i]['nonDiagramQuestions'][key]['answerChoices'].keys():\n",
        "      answerChoicesPrompt = answerChoicesPrompt + questions[i]['nonDiagramQuestions'][key]['answerChoices'][key2]['rawText'] + \"; \"\n",
        "\n",
        "    answerChoicesPrompt = answerChoicesPrompt[:-2]  \n",
        "    questionAnswerTable.append([lessonID,questionText,correctAnswerChoice, answerChoicesPrompt])\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "oAkfu6u1YrZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qat = pd.DataFrame(questionAnswerTable,columns=['id','question', 'correct answer', 'answer choices'])"
      ],
      "metadata": {
        "id": "rE6jnQ7mYyDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(qat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gNDtIvfWvJq",
        "outputId": "68bdadb8-dad7-4710-fe5d-68d08f0495cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2512"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qat.to_csv(\"qat_test.csv\")"
      ],
      "metadata": {
        "id": "icw3Bw-cYycX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For the Zero Shot Learning experiment, build a Prompt Table with just the prompt, Question plus Answer Choices. One Lesson per Row.**\n",
        "\n",
        "**For the Few Shot Learning experiment, build a Prompt Table that combines the Lesson Content and Question plus Answer Choices in a single string. One Lesson per Row.**"
      ],
      "metadata": {
        "id": "RkRMKKbeoIGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fewShotPromptInstructions = \"Use the lesson text below to answer the following questions by picking one of the choices provided. Only include the letter of the answer choice listed. For example, 3.c.\\n\\n\"\n",
        "zeroShotPromptInstructions = \"Answer the following questions by picking one of the choices provided. Only include the letter of the answer choice listed.\\n\\n\"\n",
        "\n",
        "fewShotPromptTable = []\n",
        "zeroShotPromptTable = []\n",
        "\n",
        "fewShotAnswerKeyTable = []\n",
        "zeroShotAnswerKeyTable = []\n",
        "\n",
        "for i,l in clt.iterrows():\n",
        "  fsPrompt = fewShotPromptInstructions + \"Lesson:\\n\" + l['content'] +\"\\n\\n\"+\"Questions:\\n\"\n",
        "  zsPrompt = zeroShotPromptInstructions + \"Questions:\\n\"  \n",
        "  fsAnswers = \"\"\n",
        "  lessonQAT = qat[qat.id == l['id']]\n",
        "  qnum = 1\n",
        "  for index,row in lessonQAT.iterrows():\n",
        "    fsPrompt = fsPrompt + str(qnum) + \". \" + row['question'] +\"\\n\" + row['answer choices'] + \"\\n\\n\"\n",
        "    zsPrompt = zsPrompt + str(qnum) + \". \" + row['question'] +\"\\n\" + row['answer choices'] + \"\\n\\n\"\n",
        "    fsAnswers = fsAnswers + str(qnum) + \". \" + row['correct answer'] + \"; \"\n",
        "    zeroShotAnswerKeyTable.append([l['id'],qnum,row['correct answer']])\n",
        "    qnum += 1\n",
        "      \n",
        "  fsAnswers = fsAnswers[:-2]\n",
        "\n",
        "  for i in range(qnum-1):\n",
        "    fsPrompt = fsPrompt + str(i+1) + \". ?\\n\"\n",
        "    zsPrompt = zsPrompt + str(i+1) + \". ?\\n\"\n",
        "\n",
        "  fsPrompt = fsPrompt + \"====\"\n",
        "  zsPrompt = zsPrompt + \"====\"\n",
        " \n",
        "  fewShotPromptTable.append ([l['id'],fsPrompt])\n",
        "  zeroShotPromptTable.append ([l['id'],zsPrompt])\n",
        "\n",
        "  fewShotAnswerKeyTable.append ([l['id'],fsAnswers])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "398VRBcGxLMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspt = pd.DataFrame(fewShotPromptTable,columns=['Lesson ID','Prompt'])\n",
        "fsakt = pd.DataFrame(fewShotAnswerKeyTable,columns=['Lesson ID','Answers'])\n",
        "zspt = pd.DataFrame(zeroShotPromptTable,columns=['Lesson ID','Prompt'])\n",
        "zsakt = pd.DataFrame(zeroShotAnswerKeyTable,columns=['Lesson ID','Question Number','Answer'])"
      ],
      "metadata": {
        "id": "gF65izsSxLKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspt['prompt length'] = fspt.apply(lambda x: len(str(x['Prompt'])), axis=1)"
      ],
      "metadata": {
        "id": "uxuXLjM65j47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspt.to_csv(\"fspt_test.csv\")"
      ],
      "metadata": {
        "id": "BajD-FruShmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsakt.to_csv(\"fsakt_test.csv\")\n",
        "zspt.to_csv(\"zspt_test.csv\")\n",
        "zsakt.to_csv(\"zsakt_test.csv\")"
      ],
      "metadata": {
        "id": "zXBgYvHBykE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install openai and enter my API key**"
      ],
      "metadata": {
        "id": "KY6MgHXl-_0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bPtsnWRwdUf",
        "outputId": "58a23f20-1af5-4411-a5f3-5bb4b9b84dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.7/dist-packages (0.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.7/dist-packages (from openai) (1.2.0.62)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=\"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\""
      ],
      "metadata": {
        "id": "le4jed1vyTJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some functions for calling the completions api and processing the results**"
      ],
      "metadata": {
        "id": "ZKUaLmyU_IrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to extract each individual answer out of the returned api response, into a separate row"
      ],
      "metadata": {
        "id": "oXvXDwpa4rzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response_to_table (lId, r, answer_table):\n",
        "  answer_list = r.strip().split(\"\\n\")\n",
        "  for i in answer_list:\n",
        "    row = i.split(\".\")\n",
        "    answer_table.append([lId, row[0],row[1].strip()])\n",
        "  return answer_table"
      ],
      "metadata": {
        "id": "oGDvzboFeD7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to call the api for each prompt and process the returned completion"
      ],
      "metadata": {
        "id": "l8LhX6LC5J42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lesson_answer (lId,p,answerTable):\n",
        "  import os\n",
        "  import openai\n",
        "\n",
        "  openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "  start_sequence = \"\\nA:\"\n",
        "  restart_sequence = \"\\n\\nQ: \"\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "    model=\"text-davinci-002\",\n",
        "    prompt=p,\n",
        "    temperature=0,\n",
        "    max_tokens=200,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"====\"]\n",
        "  )\n",
        "  if response['choices'][0]['finish_reason']=='stop':\n",
        "    answerTable = response_to_table (lId, response['choices'][0]['text'],answerTable)\n",
        "  \n",
        "  return answerTable"
      ],
      "metadata": {
        "id": "rsnzcsa7YC3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test out the execution on one prompt"
      ],
      "metadata": {
        "id": "lzpF1ldh5VM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "start_sequence = \"\\nA:\"\n",
        "restart_sequence = \"\\n\\nQ: \"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=\"text-davinci-002\",\n",
        "    prompt=fspt['Prompt'][2],\n",
        "    temperature=0,\n",
        "    max_tokens=200,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"====\"]\n",
        "  )"
      ],
      "metadata": {
        "id": "w4PMH-Xh-zPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (response)"
      ],
      "metadata": {
        "id": "mONHJHLm-FVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee15e880-f480-424d-c9de-a20ca9e66e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"\\n\\n1. e\\n2. d\\n3. b\\n4. c\\n5. g\\n6. a\\n7. f\\n8. a\\n9. a\\n10. b\\n11. b\\n12. b\\n13. b\\n14. a\\n15. a\\n16. b\\n17. b\\n18. d\\n19. a\\n20. d\\n21. b\\n22. a\\n23. d\\n24. d\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1663018016,\n",
            "  \"id\": \"cmpl-5plFAdwqW1kMslsyXjD3cjj5vJic2\",\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 97,\n",
            "    \"prompt_tokens\": 2181,\n",
            "    \"total_tokens\": 2278\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the few shot experiment. Since some prompts error out, we will run the experiments in batches.**"
      ],
      "metadata": {
        "id": "U9D_DpxA5Z5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultsTable = []"
      ],
      "metadata": {
        "id": "FDhGSML15pD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsetTable = fspt.iloc[0:49]\n",
        "for row in subsetTable.itertuples():\n",
        "  resultsTable = lesson_answer(row[1],row[2], resultsTable)\n"
      ],
      "metadata": {
        "id": "d0FRnjLeKOk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the Zero Shot experiment in batches**"
      ],
      "metadata": {
        "id": "XfQFKl475yUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zsResultsTable = []"
      ],
      "metadata": {
        "id": "An3QM1Oh55hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsetTable = zspt.iloc[0:49]\n",
        "for row in subsetTable.itertuples():\n",
        "  zsResultsTable = lesson_answer(row[1],row[2], zsResultsTable)"
      ],
      "metadata": {
        "id": "7EDonJ-GDbko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean up**\n",
        "\n",
        "We encounter some issues with the returned results. \n",
        "1. The actual answer is returned instead of the letter. For example, \"true\" instead of \"a\"\n",
        "2. The answer is included in addition to the the letter. For example, \"a. True\" instead of \"a\"\n",
        "\n",
        "I clean these up manually by exporting the results to a csv and fixing these issues there. Then I import the csv.\n",
        "\n",
        "Additionally, the dtypes for the Question Number needs to be set to int."
      ],
      "metadata": {
        "id": "5lI6BU0e6CMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsrat = pd.DataFrame(resultsTable,columns=['Lesson ID','Question Number','Returned Answer'])"
      ],
      "metadata": {
        "id": "_jJqXrX2gyRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zsrat = pd.DataFrame(zsResultsTable,columns=['Lesson ID','Question Number','Returned Answer'] )"
      ],
      "metadata": {
        "id": "o2NJCIdyNLLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_dict = {'Question Number': int}\n",
        "zsrat = zsrat.astype(convert_dict)"
      ],
      "metadata": {
        "id": "m3YfR5DMNj7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsrat_clean = fsrat.drop_duplicates(subset = ['Lesson ID','Question Number'],keep='first').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "8kSU1MJI3U_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsrat_clean = fsrat_clean[fsrat_clean['Lesson ID'] != 'L_0886']"
      ],
      "metadata": {
        "id": "xLJprE9J5iZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_dict = {'Question Number': int}\n",
        "fsrat_clean = fsrat_clean.astype(convert_dict)"
      ],
      "metadata": {
        "id": "G18Xz0UXdzqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zsrat_clean = pd.read_csv(\"/content/zs_answers_compared.csv\")\n",
        "zsrat = zsrat_clean.drop(['Unnamed: 0','Answer','Is Correct'],axis=1)"
      ],
      "metadata": {
        "id": "qYtHzJfrQqlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zsrat['Returned Answer'] = zsrat.apply(lambda x: 'a' if x['Returned Answer'].lower() == 'true' else 'b' if x['Returned Answer'].lower() == 'false' else x['Returned Answer'], axis=1)"
      ],
      "metadata": {
        "id": "6zDN9UorQCPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zsrat['Returned Answer'] = zsrat.apply(lambda x:  x['Returned Answer'][0], axis=1)"
      ],
      "metadata": {
        "id": "hH1JYvN8cEvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsrat_clean.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuQ2ZNuuhqdc",
        "outputId": "7732e66c-dbe0-403c-a536-65bbaa0c88d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lesson ID          object\n",
              "Question Number     int64\n",
              "Returned Answer    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a table for each experiment that compares the results returned to the answer key. These are compt (for Few Shot) and zsCompt (for Zero Shot)**"
      ],
      "metadata": {
        "id": "WYZnzXp38F-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compt = fsrat_clean.merge (zsakt,how='inner',left_on=['Lesson ID','Question Number'], right_on=['Lesson ID','Question Number'])"
      ],
      "metadata": {
        "id": "_Q1jI7YSkL0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zsCompt = zsrat.merge (zsakt,how='inner',left_on=['Lesson ID','Question Number'], right_on=['Lesson ID','Question Number'])"
      ],
      "metadata": {
        "id": "xlHEtPLoNssN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the returned answer to the answer from the answer key, and set \"Is Correct\" to True if they are equal, and False if not equal**"
      ],
      "metadata": {
        "id": "9Al6vjYq8YMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compt['Is Correct'] = compt.apply(lambda x: x['Answer'] == x['Returned Answer'], axis=1)"
      ],
      "metadata": {
        "id": "WahGfTITnJo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zsCompt['Is Correct'] = zsCompt.apply(lambda x: x['Answer'] == x['Returned Answer'], axis=1)"
      ],
      "metadata": {
        "id": "13uD3RyyN4tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero Shot Accuracy**"
      ],
      "metadata": {
        "id": "85Xr9f2gRSsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(zsCompt[zsCompt['Is Correct']==True])/len(zsCompt)"
      ],
      "metadata": {
        "id": "bfKpyPZ1OE3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compt.to_csv(\"fs_answers_compared.csv\")\n",
        "zsCompt.to_csv(\"zs_answers_compared.csv\")"
      ],
      "metadata": {
        "id": "GOXC5ibivleQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few Shot Accuracy**"
      ],
      "metadata": {
        "id": "OnID7rWyRW0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some prompts from the Few Shot experiment had to be re-run manually in the playground. I exported the answers into a CSV, recorded the answers from the playground manually and imported the updated CSV."
      ],
      "metadata": {
        "id": "DKR9VZVK9R5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsCompt = pd.read_csv(\"/content/fs_answers_compared_fixed_playground.csv\")"
      ],
      "metadata": {
        "id": "6d69yayBjaQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fsCompt[fsCompt['Is Correct']==1])/len(fsCompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqFNiSzVkaOC",
        "outputId": "8b914504-a011-47ce-e0da-43f28a554740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8483927019982623"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_results_table = zsCompt.merge (fsCompt,how='inner',left_on=['Lesson ID','Question Number'], right_on=['Lesson ID','Question Number'],suffixes=('_zs','_fs'))"
      ],
      "metadata": {
        "id": "iNcp6o8Dh4L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2dcM4Zter6bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stats on the combined results - 2,254 Questions and Answers for 179 lessons were run in both experiments. These were compared.**"
      ],
      "metadata": {
        "id": "UmsBJzf_97qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_results_table.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYFGYTp2i8tc",
        "outputId": "21418654-b1fc-458b-d0e5-e8312eb762ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lesson ID             179\n",
              "Question Number        34\n",
              "Returned Answer_zs     11\n",
              "Answer_zs               7\n",
              "Is Correct_zs           2\n",
              "Returned Answer_fs     10\n",
              "Answer_fs               7\n",
              "Is Correct_fs           2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(combined_results_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlLqKoAKRgbC",
        "outputId": "5db09aed-955e-4ed4-9463-2b81b49e5756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2254"
            ]
          },
          "metadata": {},
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison of Accuracy for the common questions**"
      ],
      "metadata": {
        "id": "fQffo-erShyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Zero Shot Accuracy: \" + str(len(combined_results_table[combined_results_table['Is Correct_zs']==True])/len(combined_results_table)) + \"  Few Shot Accuracy: \" + str(len(combined_results_table[combined_results_table['Is Correct_fs']==True])/len(combined_results_table)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpkYBEsCRwOh",
        "outputId": "af70f915-9c48-4204-8869-34144bb23030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero Shot Accuracy: 0.7275953859804791  Few Shot Accuracy: 0.8478260869565217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_results_table.to_csv(\"combined_results_final.csv\")"
      ],
      "metadata": {
        "id": "pgSBjBOtsOmf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}